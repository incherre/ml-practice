# Week 2
## Question 1
By some definitions, a chess AI has the goal of winning. When is it useful to describe it that way? What are the key differences between human goals and the "goals" of a chess AI?
### My original answer
Useful when youâ€™re trying to predict what moves it may make, or what the outcome of a match it is in might be. Human goals are not easily encodable, and have many complex considerations.
### Answer co-written with an LLM
Describing a chess AI as having the goal of winning is useful when predicting its moves or anticipating match outcomes. Unlike human goals, which are not easily encodable and involve complex considerations, a chess AI's goal of winning is well-defined and focused on optimizing its performance in the game. While human goals encompass a wide range of factors, the goals of a chess AI are specifically tailored to achieving victory in the game of chess.
## Question 2
Why is it not appropriate to describe the agents from Krakovna et al. (2020) as displaying inner alignment failures?
### My original answer
Because the agents are actually maximizing the reward function as given to the outer optimizer.
### Answer co-written with an LLM
It is not appropriate to describe the agents from Krakovna et al. (2020) as displaying inner alignment failures because these agents are successfully maximizing the reward function as provided by the operator. Their behavior aligns with the given reward function, indicating that the agents are effectively pursuing the specified objectives.